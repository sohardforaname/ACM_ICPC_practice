/*

各位观众大家好，欢迎收看test小组的计算机组成原理课程设计的展示视频，我是这次展示的汇报人，莫琛辉，我们小组的课题是，基于kNN算法的手写数字识别。
这次的展示分为5个步骤

首先是项目介绍，其次是人员分工，接下来是原理分析，然后是效果展示，最后是优化和展望。

首先是项目简介，这个项目是在五段气泡流水线的CPU上实现kNN算法，完成手写数字识别的项目。
为什么选择这个项目，其一是加载自定义图像和输出预测的图像的结果使得这个项目有了完整的输入输出系统。我们需要在CPU上增加自己的系统调用，这对于流水线的原理需要有一定的了解
其二是因为图片数据一般来说是数据量较大的一种数据形式，kNN又是一种需要大量计算的算法，所以算法的优化显得尤为重要，这就让我很好的复习了机器学习课和算法课上教的算法优化技术，
起到学科交叉和发散思维的目的。

然后是人员分工介绍，我们队的队员主有三人，分别是我（队长），赵晓刚，倪佳维。赵晓刚主要负责标准图像和默认测试集的设计，预测结果显示电路的设计，团队日志的编写和PPT的框架设计和撰写
倪佳维主要是负责编写mips-gcc汇编代码，因为使用mips-gcc编译的代码较难看懂，并且没有结构性，不方便优化，和优化汇编代码长度和效率，同时做指令集的优化，因为CPU指令集的限制。
我主要是负责kNN算法和位运算算法的优化。输入系统调用的设计和PPT的撰写和校对。

接下来是本次展示的重点，原理分析。

首先是标准图像和非标准图像的格式是32bit整数。
然后是输入系统，在Syscall指令到来时，系统会停下来等待输入，输入时支持手工调整输入和直接输入一个整数，然后按下按钮后触发寄存器的上升沿更新，数据就写入了寄存器中。
显示结果也是使用Syscall指令，并且设置$a0是34的时候，触发LED寄存器的数据更新和锁存。

然后是kNN算法的介绍：
kNN算法是一种分类算法，对于一个测试数据，我们假定它们之间的相似度可以用它们之间的欧氏距离衡量，这样子，我们计算这个测试集和数据集的所有数据的欧几里得距离，然后选出前k大，
在前k大中选出占比最多的类别作为测试集的类别。
对于点阵图片，每一位上只有0或者1，所以计算距离实际上是异或计算，然后统计异或后的数字的二进制表示的1的数量就是距离，所以统计1的数量的效率决定了系统的效率。
接下来介绍两种算法，一种是lowbit，一种是popcount算法。
lowbit算法是被大量运用在二叉索引树（树状数组）和状态压缩算法的位运算算法，它可以计算出一个二进制数中最低位的1的位置pos，并返回2^pos，因此，我们只需要每次让这个数减去它的lowbit，直到0。
相减的次数就是这个数的1的数量。lowbit的实现方法就是a&(-a)，在树状数组上，它用于快速计算树状数组的位置索引，实现快速计算前缀和。
我们可以证明，lowbit算法统计一个数的二进制表示的1的数量的期望时间复杂度是O(loglogn)，
popcount算法是基于分治法的纯位运算的算法，它被GNU GCC的扩展位运算库实现，时间复杂度是O(logloglogn)。

我们最终考虑使用popcount算法。

接下来是指令集优化和调整。
我们在做的时候发现mips CPU没有指令支持一次往寄存器里面加载一个32bit立即数，mips的汇编器总是会尝试使用lui指令，
但是这个指令我们没有实现，所以我们就使用了ori和sll配合的指令，指令数量和使用lui的情况是一样的。

然后就是图片标签的保存，考虑到距离的最大值只有32，我们直接让距离值左移16位，然后把图片的标签压在距离的低半字，这样子不影响排序结果同时也成功保存了图片标签。

最后是下一步的优化的设想和展望。
一个是优化的kNN算法时钟周期数仍然太长，所以需要使用动态分支预测的重定向流水线优化硬件，
同时继续优化算法，尽可能提升算法的理论性能，或者引入并行计算。
*/